# Project Structure - Network Anomaly Detection System

This document describes the professional organization of the Network Anomaly Detection System codebase.

## ğŸ“ Directory Structure

```
CTS/  (Project Root)
â”œâ”€â”€ main.py                 # ğŸš€ Main entry point - run this to execute the system
â”œâ”€â”€ README.md              # ğŸ“– Project overview and quick start guide
â”œâ”€â”€ requirements.txt       # ğŸ“¦ Python dependencies
â”œâ”€â”€ .gitignore            # ğŸš« Git ignore patterns
â”‚
â”œâ”€â”€ src/                   # ğŸ’» Source Code
â”‚   â”œâ”€â”€ main.py               # Pipeline orchestrator
â”‚   â”œâ”€â”€ config.py             # Configuration and parameters
â”‚   â”œâ”€â”€ data_loader.py        # Data loading and validation
â”‚   â”œâ”€â”€ explorer.py           # Exploratory data analysis
â”‚   â”œâ”€â”€ preprocessor.py       # Data preprocessing and feature engineering
â”‚   â””â”€â”€ model_trainer.py      # Model training and evaluation
â”‚
â”œâ”€â”€ data/                  # ğŸ“Š Raw Data Files
â”‚   â”œâ”€â”€ ML-MATT-CompetitionQT1920_train.csv
â”‚   â””â”€â”€ ML-MATT-CompetitionQT1920_test.csv
â”‚
â”œâ”€â”€ results/               # ğŸ“ˆ Generated Outputs
â”‚   â”œâ”€â”€ predictions.csv           # Detailed predictions with probabilities
â”‚   â”œâ”€â”€ simple_predictions.csv    # Competition submission format
â”‚   â”œâ”€â”€ exploration.png           # Data exploration visualizations
â”‚   â””â”€â”€ [other generated files]   # Various analysis outputs
â”‚
â”œâ”€â”€ docs/                  # ğŸ“š Documentation
â”‚   â”œâ”€â”€ documentation.txt         # Complete project documentation
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md     # This file - project organization
â”‚   â”œâ”€â”€ SIMPLE_README.md          # Technical implementation details
â”‚   â”œâ”€â”€ SIMPLIFICATION_SUMMARY.md # Development history
â”‚   â””â”€â”€ TEST_SUMMARY.md           # Testing and validation report
â”‚
â”œâ”€â”€ tests/                 # ğŸ§ª Testing and Validation
â”‚   â””â”€â”€ test_outputs.py           # Output validation tests
â”‚
â”œâ”€â”€ config/                # âš™ï¸ Configuration Files
â”‚   â””â”€â”€ requirements.txt      # Python package requirements
â”‚
â”œâ”€â”€ models/                # ğŸ¤– Model Artifacts
â”‚   â”œâ”€â”€ cellname_encoder.joblib   # Trained categorical encoder
â”‚   â””â”€â”€ feature_scaler.joblib     # Trained feature scaler
â”‚
â””â”€â”€ scripts/               # ğŸ› ï¸ Utility Scripts
    â””â”€â”€ [future utility scripts]
```

## ğŸ¯ Key Components

### Entry Points
- **`main.py`**: Professional entry point that can be run from project root
- **`src/main.py`**: Core pipeline implementation

### Core Modules
- **`config.py`**: Centralized configuration management
- **`data_loader.py`**: Robust data loading with encoding handling
- **`explorer.py`**: Data analysis and visualization
- **`preprocessor.py`**: Feature engineering and data cleaning
- **`model_trainer.py`**: Machine learning pipeline

### Data Flow
```
data/ â†’ src/data_loader.py â†’ src/preprocessor.py â†’ src/model_trainer.py â†’ results/
```

## ğŸš€ Usage Patterns

### Standard Usage
```bash
# From project root
python main.py
```

### Development/Testing
```bash
# Individual component testing
python src/data_loader.py
python src/preprocessor.py
python src/model_trainer.py

# Validation
python tests/test_outputs.py
```

### Configuration
- Modify `src/config.py` for parameters
- Update `requirements.txt` for dependencies
- Check `config/` for additional settings

## ğŸ”„ Data Flow

1. **Data Loading**: `data/` â†’ `src/data_loader.py`
2. **Exploration**: Training data â†’ `src/explorer.py` â†’ visualizations
3. **Preprocessing**: Raw data â†’ `src/preprocessor.py` â†’ engineered features
4. **Training**: Features â†’ `src/model_trainer.py` â†’ trained models
5. **Prediction**: Test data â†’ trained model â†’ `results/predictions.csv`
6. **Validation**: `tests/test_outputs.py` validates all outputs

## ğŸ“Š Output Organization

### Primary Results
- `results/predictions.csv`: Complete predictions with probabilities and original data
- `results/simple_predictions.csv`: Clean competition/submission format

### Analysis Outputs
- `results/exploration.png`: Data visualization plots
- `results/[various].txt`: Analysis reports and summaries

### Model Artifacts
- `models/`: Serialized encoders and scalers for reproducibility

## ğŸ§ª Testing Strategy

- **Component Tests**: Each module can be run independently
- **Integration Tests**: `main.py` runs the complete pipeline
- **Output Validation**: `tests/test_outputs.py` verifies all generated files
- **Documentation**: All processes documented in `docs/documentation.txt`

## ğŸ”§ Development Workflow

1. **Setup**: Install requirements from `requirements.txt`
2. **Data**: Ensure CSV files are in `data/` directory
3. **Development**: Modify modules in `src/`
4. **Testing**: Run individual modules and `tests/test_outputs.py`
5. **Execution**: Run `python main.py` for complete pipeline
6. **Results**: Review outputs in `results/` directory
7. **Documentation**: Update `docs/documentation.txt` as needed

## ğŸ“ˆ Professional Features

- **Separation of Concerns**: Clear separation between data, code, results, and documentation
- **Reproducibility**: All paths and configurations centralized
- **Testing**: Comprehensive validation of outputs
- **Documentation**: Complete project documentation
- **Version Control**: Professional `.gitignore` for Python projects
- **Entry Points**: Multiple ways to run the system (development vs production)

## ğŸš€ Future Enhancements

The structure supports:
- Additional model implementations in `src/`
- More comprehensive tests in `tests/`
- Utility scripts in `scripts/`
- Extended documentation in `docs/`
- Multiple configuration files in `config/`
- Model versioning in `models/`

This professional structure ensures maintainability, scalability, and collaboration readiness.
